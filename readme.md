
```markdown
# ğŸ¤– API de DÃ©tection d'Ã‰motions Faciales

Ce projet est un prototype d'API d'analyse Ã©motionnelle. Son objectif est de dÃ©tecter un visage dans une image fournie, de prÃ©dire l'Ã©motion de ce visage Ã  l'aide d'un modÃ¨le de Deep Learning (CNN), et d'enregistrer le rÃ©sultat dans une base de donnÃ©es PostgreSQL.

Ce prototype sert Ã  valider la faisabilitÃ© technique d'un futur produit SaaS destinÃ© Ã  l'analyse de rÃ©actions utilisateurs (UX, tests produits).

## âœ¨ FonctionnalitÃ©s

* **DÃ©tection de Visage** : Utilise OpenCV et le classifieur Haar Cascade pour localiser automatiquement les visages dans une image.
* **PrÃ©diction d'Ã‰motion** : Emploie un modÃ¨le de rÃ©seau de neurones convolutif (CNN) entraÃ®nÃ© avec TensorFlow/Keras pour classifier l'Ã©motion (ex: joie, tristesse, colÃ¨re, surprise).
* **API RESTful** : Une API FastAPI expose deux points de terminaison :
    * `POST /predict_emotion` : ReÃ§oit une image, effectue la dÃ©tection et la prÃ©diction, et sauvegarde le rÃ©sultat.
    * `GET /history` : Renvoie l'historique de toutes les prÃ©dictions stockÃ©es.
* **Persistance des DonnÃ©es** : Chaque prÃ©diction rÃ©ussie est enregistrÃ©e dans une base de donnÃ©es PostgreSQL via SQLAlchemy.

## ğŸ› ï¸ Stack Technique

* **Python 3.10+**
* **ModÃ¨le IA** : TensorFlow / Keras (pour le CNN), OpenCV (pour Haar Cascade)
* **API** : FastAPI
* **Base de DonnÃ©es** : PostgreSQL
* **ORM** : SQLAlchemy
* **Tests** : Pytest
* **CI/CD** : GitHub Actions

## ğŸ“‚ Structure du Projet

```


â”œâ”€â”€ .github/workflows/

â”‚                 â””â”€â”€ demo.yml           \# Workflow GitHub Actions pour les tests

â”œâ”€â”€ dataset/

â”‚         â””â”€â”€ test/
      
â”‚         â””â”€â”€ train/
â”œâ”€â”€ images/        \# Dossier oÃ¹ les images testÃ©es ont Ã©tÃ© enregistrÃ©es

â”œâ”€â”€ pipeline/

â”‚        â””â”€â”€ detect_and_predict.py       \# contient la fonction dâ€™entraÃ®nement et de prÃ©diction

â”œâ”€â”€ tests/

â”‚      â””â”€â”€ test_model_prediction.py        \# Tests unitaires

â”œâ”€â”€ .env           \# Fichier d'exemple pour les variables d'environnement

â”œâ”€â”€ main.py                \# Fichier principal de l'API FastAPI

â”œâ”€â”€ requirements.txt       \# DÃ©pendances Python

â”œâ”€â”€ best_model.keras       \# Le modÃ¨le CNN entraÃ®nÃ©

â””â”€â”€ README.md              \# documentation

````

## ğŸš€ Installation et Lancement

Suivez ces Ã©tapes pour configurer et lancer le projet localement.

### 1. PrÃ©requis

* Python 3.10 ou supÃ©rieur
* Un serveur PostgreSQL en cours d'exÃ©cution

### 2. Cloner le DÃ©pÃ´t

```bash
git clone <url-de-votre-depot>
cd <nom-du-depot>
````

### 3\. Configurer l'Environnement

CrÃ©ez et activez un environnement virtuel :

```bash
python -m venv venv
# Sur Windows
venv\Scripts\activate
# Sur macOS/Linux
source venv/bin/activate
```

Installez les dÃ©pendances :

```bash
pip install -r requirements.txt
```

### 4\. Configurer la Base de DonnÃ©es

CrÃ©ez un fichier `.env` Ã  la racine du projet par exemple:

**Fichier `.env` :**

```ini
# 
DATABASE_NAME= "exe_name"
DATABASE_PASSWORD="exe_pass"
DATABASE_PORT=5432
DATABASE_HOST="localhost"
DATABASE_USER= "exe_password"

```

### 5\. Lancer l'API

Utilisez `uvicorn` pour dÃ©marrer le serveur FastAPI :

```bash
uvicorn main:app --reload
```

L'API est maintenant accessible Ã  l'adresse `http://127.0.0.1:8000`. La documentation interactive (Swagger UI) est disponible sur `http://127.0.0.1:8000/docs`.

## ğŸ“ˆ Utilisation de l'API

### `POST /predict_emotion`

Ce point de terminaison permet de soumettre une image pour analyse.

**Exemple avec `curl` :**

```bash
 visitez ce lien: 
 [http://127.0.0.1:8000/predict_emotion]
```

**RÃ©ponse Attendue (SuccÃ¨s) :**

```json
{
  "emotion": "happy",
  "confidence": 0.92,
}
```

### `GET /history`

Ce point de terminaison renvoie la liste de toutes les prÃ©dictions enregistrÃ©es.


**RÃ©ponse Attendue :**

```json
[
  {
    "id": 1,
    "emotion": "happy",
    "confidence": 0.92,
    "created_at": "2025-11-14T15:30:00Z"
  },
  {
    "id": 2,
    "emotion": "surprised",
    "confidence": 0.78,
    "created_at": "2025-11-14T15:31:12Z"
  }
]
```

## ğŸ§© Composants ClÃ©s

### 1\. EntraÃ®nement du ModÃ¨le (`Emotion_CNN_Training.ipynb`)

Le notebook Jupyter dÃ©taille les Ã©tapes de :

  * Chargement des donnÃ©es avec `tf.keras.utils.image_dataset_from_directory`.
  * PrÃ©traitement (normalisation, augmentation des donnÃ©es).
  * Construction du modÃ¨le CNN (Conv2D, MaxPooling2D, Dropout, Dense).
  * EntraÃ®nement (`adam`, `categorical_crossentropy`).
  * Ã‰valuation et sauvegarde du modÃ¨le avec keras.

### 2\. Script de Test (`detect_and_predict.py`)

Ce script permet de tester le pipeline complet (OpenCV + Keras) sur une seule image sans dÃ©marrer l'API.

### 3\. Tests et CI/CD

Les tests unitaires vÃ©rifient :

  * Le chargement correct du modÃ¨le.
  * Le format de la rÃ©ponse de prÃ©diction.

Le workflow GitHub Actions (dÃ©fini dans `.github/workflows/demo.yml`) exÃ©cute ces tests automatiquement Ã  chaque `push` ou `pull_request` sur les branches `main` et `develop`, en utilisant un service PostgreSQL pour l'intÃ©gration.

Pour lancer les tests localement :

```bash
pytest -v
```
